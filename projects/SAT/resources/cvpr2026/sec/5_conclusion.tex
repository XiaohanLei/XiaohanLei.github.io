\vspace{-6pt}
\section{Conclusion}
\vspace{-4pt}

In this work, we introduce a fundamental shift in action representation for policy learning, challenging the conventional temporal-centric paradigm.
We propose a \textit{structural-centric} representation, which models an action chunk as a variable-length sequence of joint-wise trajectories.
We demonstrate that this structural formulation provides a
powerful framework for tackling cross-embodiment skill
transfer in high-DoF dexterous hands.
Through comprehensive evaluation across both simulation and real-world bimanual manipulation tasks, our method consistently outperforms all baselines.
Our results highlight that a structural-centric prior enables temporal compression and allows the policy to bridge the morphological gap between demonstrators and robots.
In future research, this structural action representation will be extended beyond imitation learning, investigating its potential as an expressive policy class for reinforcement learning, where it could offer a structured exploration space for complex high-DoF agents.



