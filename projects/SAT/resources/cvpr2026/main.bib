@string{CVPR = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}}
@string{ICRA ={Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)}}
@string{IROS ={Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}}
@string{NIPS ={Proceedings of the Advances in Neural Information Processing Systems (NeurIPS)}}
@string{CORL ={Proceedings of the Conference on Robot Learning (CoRL)}}
@string{ICCV ={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)}}
@string{ICML ={Proceedings of the International Conference on Machine Learning (ICML)}}
@string{ICLR ={Proceedings of the International Conference on Learning Representations (ICLR)}}
@string{AAAI ={Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)}}
@string{RSS ={Proceedings of the Robotics: Science and Systems (RSS)}}


@article{pomerleau1988alvinn,
  title={Alvinn: An autonomous land vehicle in a neural network},
  author={Pomerleau, Dean A},
  journal=NIPS,
  volume={1},
  year={1988}
}

@inproceedings{bicchi2000robotic,
  title={Robotic grasping and contact: A review},
  author={Bicchi, Antonio and Kumar, Vijay},
  booktitle=ICRA,
  volume={1},
  pages={348--353},
  year={2000},
  organization={IEEE}
}

@inproceedings{ross2010efficient,
  title={Efficient reductions for imitation learning},
  author={Ross, St{\'e}phane and Bagnell, Drew},
  booktitle={Proceedings of the International Conference on Artificial Intelligence and Statistics (ICAIS)},
  pages={661--668},
  year={2010},
  organization={JMLR Workshop and Conference Proceedings}
}

@inproceedings{ross2011reduction,
  title={A reduction of imitation learning and structured prediction to no-regret online learning},
  author={Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
  booktitle={Proceedings of the International Conference on Artificial Intelligence and Statistics (ICAIS)},
  pages={627--635},
  year={2011},
  organization={JMLR Workshop and Conference Proceedings}
}

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle=IROS,
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}

@book{murray2017mathematical,
  title={A mathematical introduction to robotic manipulation},
  author={Murray, Richard M and Li, Zexiang and Sastry, S Shankar},
  year={2017},
  publisher={CRC press}
}

@inproceedings{qi2017pointnet,
  title={Pointnet: Deep learning on point sets for 3d classification and segmentation},
  author={Qi, Charles R and Su, Hao and Mo, Kaichun and Guibas, Leonidas J},
  booktitle=CVPR,
  pages={652--660},
  year={2017}
}

@article{rajeswaran2017learning,
  title={Learning complex dexterous manipulation with deep reinforcement learning and demonstrations},
  author={Rajeswaran, Aravind and Kumar, Vikash and Gupta, Abhishek and Vezzani, Giulia and Schulman, John and Todorov, Emanuel and Levine, Sergey},
  journal={arXiv preprint arXiv:1709.10087},
  year={2017}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal=NIPS,
  volume={30},
  year={2017}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}

@inproceedings{mandlekar2018roboturk,
  title={Roboturk: A crowdsourcing platform for robotic skill learning through imitation},
  author={Mandlekar, Ajay and Zhu, Yuke and Garg, Animesh and Booher, Jonathan and Spero, Max and Tung, Albert and Gao, Julian and Emmons, John and Gupta, Anchit and Orbay, Emre and others},
  booktitle=CORL,
  pages={879--893},
  year={2018},
  organization={PMLR}
}

@article{sharma2019dynamics,
  title={Dynamics-aware unsupervised discovery of skills},
  author={Sharma, Archit and Gu, Shixiang and Levine, Sergey and Kumar, Vikash and Hausman, Karol},
  journal={arXiv preprint arXiv:1907.01657},
  year={2019}
}

@article{dasari2019robonet,
  title={Robonet: Large-scale multi-robot learning},
  author={Dasari, Sudeep and Ebert, Frederik and Tian, Stephen and Nair, Suraj and Bucher, Bernadette and Schmeckpeper, Karl and Singh, Siddharth and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:1910.11215},
  year={2019}
}

@article{2020t5,
  author  = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  title   = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  journal = {Journal of Machine Learning Research},
  year    = {2020},
  volume  = {21},
  number  = {140},
  pages   = {1-67},
  url     = {http://jmlr.org/papers/v21/20-074.html}
}


@inproceedings{nagabandi2020deep,
  title={Deep dynamics models for learning dexterous manipulation},
  author={Nagabandi, Anusha and Konolige, Kurt and Levine, Sergey and Kumar, Vikash},
  booktitle=CORL,
  pages={1101--1112},
  year={2020},
  organization={PMLR}
}

@article{andrychowicz2020learning,
  title={Learning dexterous in-hand manipulation},
  author={Andrychowicz, OpenAI: Marcin and Baker, Bowen and Chociej, Maciek and Jozefowicz, Rafal and McGrew, Bob and Pachocki, Jakub and Petron, Arthur and Plappert, Matthias and Powell, Glenn and Ray, Alex and others},
  journal={The International Journal of Robotics Research},
  volume={39},
  number={1},
  pages={3--20},
  year={2020},
  publisher={SAGE Publications Sage UK: London, England}
}



@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of machine learning research},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}

@article{makoviychuk2021isaac,
  title={Isaac gym: High performance gpu-based physics simulation for robot learning},
  author={Makoviychuk, Viktor and Wawrzyniak, Lukasz and Guo, Yunrong and Lu, Michelle and Storey, Kier and Macklin, Miles and Hoeller, David and Rudin, Nikita and Allshire, Arthur and Handa, Ankur and others},
  journal={arXiv preprint arXiv:2108.10470},
  year={2021}
}

@article{bommasani2021opportunities,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}

@article{lipman2022flow,
  title={Flow matching for generative modeling},
  author={Lipman, Yaron and Chen, Ricky TQ and Ben-Hamu, Heli and Nickel, Maximilian and Le, Matt},
  journal={arXiv preprint arXiv:2210.02747},
  year={2022}
}

@article{janner2022planning,
  title={Planning with diffusion for flexible behavior synthesis},
  author={Janner, Michael and Du, Yilun and Tenenbaum, Joshua B and Levine, Sergey},
  journal={arXiv preprint arXiv:2205.09991},
  year={2022}
}

@article{reed2022generalist,
  title={A generalist agent},
  author={Reed, Scott and Zolna, Konrad and Parisotto, Emilio and Colmenarejo, Sergio Gomez and Novikov, Alexander and Barth-Maron, Gabriel and Gimenez, Mai and Sulsky, Yury and Kay, Jackie and Springenberg, Jost Tobias and others},
  journal={arXiv preprint arXiv:2205.06175},
  year={2022}
}

@article{brohan2022rt,
  title={Rt-1: Robotics transformer for real-world control at scale},
  author={Brohan, Anthony and Brown, Noah and Carbajal, Justice and Chebotar, Yevgen and Dabis, Joseph and Finn, Chelsea and Gopalakrishnan, Keerthana and Hausman, Karol and Herzog, Alex and Hsu, Jasmine and others},
  journal={arXiv preprint arXiv:2212.06817},
  year={2022}
}

@inproceedings{liu2022hoi4d,
  title={Hoi4d: A 4d egocentric dataset for category-level human-object interaction},
  author={Liu, Yunze and Liu, Yun and Jiang, Che and Lyu, Kangbo and Wan, Weikang and Shen, Hao and Liang, Boqiang and Fu, Zhoujie and Wang, He and Yi, Li},
  booktitle=CVPR,
  pages={21013--21022},
  year={2022}
}

@article{nair2022r3m,
  title={R3m: A universal visual representation for robot manipulation},
  author={Nair, Suraj and Rajeswaran, Aravind and Kumar, Vikash and Finn, Chelsea and Gupta, Abhinav},
  journal={arXiv preprint arXiv:2203.12601},
  year={2022}
}

@article{fang2023rh20t,
  title={Rh20t: A comprehensive robotic dataset for learning diverse skills in one-shot},
  author={Fang, Hao-Shu and Fang, Hongjie and Tang, Zhenyu and Liu, Jirong and Wang, Chenxi and Wang, Junbo and Zhu, Haoyi and Lu, Cewu},
  journal={arXiv preprint arXiv:2307.00595},
  year={2023}
}

@article{driess2023palm,
  title={Palm-e: An embodied multimodal language model},
  author={Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and Lynch, Corey and Chowdhery, Aakanksha and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and Huang, Wenlong and others},
  year={2023}
}

@inproceedings{walke2023bridgedata,
  title={Bridgedata v2: A dataset for robot learning at scale},
  author={Walke, Homer Rich and Black, Kevin and Zhao, Tony Z and Vuong, Quan and Zheng, Chongyi and Hansen-Estruch, Philippe and He, Andre Wang and Myers, Vivek and Kim, Moo Jin and Du, Max and others},
  booktitle=CORL,
  pages={1723--1736},
  year={2023},
  organization={PMLR}
}

@article{reuss2023goal,
  title={Goal-conditioned imitation learning using score-based diffusion policies},
  author={Reuss, Moritz and Li, Maximilian and Jia, Xiaogang and Lioutikov, Rudolf},
  journal={arXiv preprint arXiv:2304.02532},
  year={2023}
}

@inproceedings{zitkovich2023rt,
  title={Rt-2: Vision-language-action models transfer web knowledge to robotic control},
  author={Zitkovich, Brianna and Yu, Tianhe and Xu, Sichun and Xu, Peng and Xiao, Ted and Xia, Fei and Wu, Jialin and Wohlhart, Paul and Welker, Stefan and Wahid, Ayzaan and others},
  booktitle=CORL,
  pages={2165--2183},
  year={2023},
}

@inproceedings{bao2023dexart,
  title={Dexart: Benchmarking generalizable dexterous manipulation with articulated objects},
  author={Bao, Chen and Xu, Helin and Qin, Yuzhe and Wang, Xiaolong},
  booktitle=CVPR,
  pages={21190--21200},
  year={2023}
}

@inproceedings{peebles2023scalable,
  title={Scalable diffusion models with transformers},
  author={Peebles, William and Xie, Saining},
  booktitle=CVPR,
  pages={4195--4205},
  year={2023}
}

@article{chi2023diffusion,
  title={Diffusion policy: Visuomotor policy learning via action diffusion},
  author={Chi, Cheng and Xu, Zhenjia and Feng, Siyuan and Cousineau, Eric and Du, Yilun and Burchfiel, Benjamin and Tedrake, Russ and Song, Shuran},
  journal={The International Journal of Robotics Research},
  pages={02783649241273668},
  year={2023},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{qin2023anyteleop,
  title={Anyteleop: A general vision-based dexterous robot arm-hand teleoperation system},
  author={Qin, Yuzhe and Yang, Wei and Huang, Binghao and Van Wyk, Karl and Su, Hao and Wang, Xiaolong and Chao, Yu-Wei and Fox, Dieter},
  journal={arXiv preprint arXiv:2307.04577},
  year={2023}
}

@article{zhao2023learning,
  title={Learning fine-grained bimanual manipulation with low-cost hardware},
  author={Zhao, Tony Z and Kumar, Vikash and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:2304.13705},
  year={2023}
}

@article{chen2023bi,
  title={Bi-dexhands: Towards human-level bimanual dexterous manipulation},
  author={Chen, Yuanpei and Geng, Yiran and Zhong, Fangwei and Ji, Jiaming and Jiang, Jiechuang and Lu, Zongqing and Dong, Hao and Yang, Yaodong},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={46},
  number={5},
  pages={2804--2818},
  year={2023},
  publisher={IEEE}
}

@inproceedings{pan2023aria,
  title={Aria digital twin: A new benchmark dataset for egocentric 3d machine perception},
  author={Pan, Xiaqing and Charron, Nicholas and Yang, Yongqian and Peters, Scott and Whelan, Thomas and Kong, Chen and Parkhi, Omkar and Newcombe, Richard and Ren, Yuheng Carl},
  booktitle=CVPR,
  pages={20133--20143},
  year={2023}
}

@article{huang2023voxposer,
  title={Voxposer: Composable 3d value maps for robotic manipulation with language models},
  author={Huang, Wenlong and Wang, Chen and Zhang, Ruohan and Li, Yunzhu and Wu, Jiajun and Fei-Fei, Li},
  journal={arXiv preprint arXiv:2307.05973},
  year={2023}
}

@article{wang2024dexcap,
  title = {DexCap: Scalable and Portable Mocap Data Collection System for Dexterous Manipulation},
  author = {Wang, Chen and Shi, Haochen and Wang, Weizhuo and Zhang, Ruohan and Fei-Fei, Li and Liu, C. Karen},
  journal = {arXiv preprint arXiv:2403.07788},
  year = {2024}
}

@inproceedings{grauman2024ego,
  title={Ego-exo4d: Understanding skilled human activity from first-and third-person perspectives},
  author={Grauman, Kristen and Westbury, Andrew and Torresani, Lorenzo and Kitani, Kris and Malik, Jitendra and Afouras, Triantafyllos and Ashutosh, Kumar and Baiyya, Vijay and Bansal, Siddhant and Boote, Bikram and others},
  booktitle=CVPR,
  pages={19383--19400},
  year={2024}
}

@article{zhen20243d,
  title={3d-vla: A 3d vision-language-action generative world model},
  author={Zhen, Haoyu and Qiu, Xiaowen and Chen, Peihao and Yang, Jincheng and Yan, Xin and Du, Yilun and Hong, Yining and Gan, Chuang},
  journal={arXiv preprint arXiv:2403.09631},
  year={2024}
}

@article{wang2024scaling,
  title={Scaling proprioceptive-visual learning with heterogeneous pre-trained transformers},
  author={Wang, Lirui and Chen, Xinlei and Zhao, Jialiang and He, Kaiming},
  journal= NIPS,
  volume={37},
  pages={124420--124450},
  year={2024}
}

@article{cheng2024open,
  title={Open-television: Teleoperation with immersive active visual feedback},
  author={Cheng, Xuxin and Li, Jialong and Yang, Shiqi and Yang, Ge and Wang, Xiaolong},
  journal={arXiv preprint arXiv:2407.01512},
  year={2024}
}

@inproceedings{zheng2024tracevla,
  title={Tracevla: Visual trace prompting enhances spatial-temporal awareness for generalist robotic policies},
  author={Zheng, Ruijie and Liang, Yongyuan and Huang, Shuaiyi and Gao, Jianfeng and Daum{\'e} III, Hal and Kolobov, Andrey and Huang, Furong and Yang, Jianwei},
  booktitle=ICLR,
  year={2024}
}

@article{team2024octo,
  title={Octo: An open-source generalist robot policy},
  author={Team, Octo Model and Ghosh, Dibya and Walke, Homer and Pertsch, Karl and Black, Kevin and Mees, Oier and Dasari, Sudeep and Hejna, Joey and Kreiman, Tobias and Xu, Charles and others},
  journal={arXiv preprint arXiv:2405.12213},
  year={2024}
}

@inproceedings{o2024open,
  title={Open x-embodiment: Robotic learning datasets and rt-x models: Open x-embodiment collaboration 0},
  author={Oâ€™Neill, Abby and Rehman, Abdul and Maddukuri, Abhiram and Gupta, Abhishek and Padalkar, Abhishek and Lee, Abraham and Pooley, Acorn and Gupta, Agrim and Mandlekar, Ajay and Jain, Ajinkya and others},
  booktitle=ICRA,
  pages={6892--6903},
  year={2024},
}

@article{ze20243d,
  title={3d diffusion policy: Generalizable visuomotor policy learning via simple 3d representations},
  author={Ze, Yanjie and Zhang, Gu and Zhang, Kangning and Hu, Chenyuan and Wang, Muhan and Xu, Huazhe},
  journal={arXiv preprint arXiv:2403.03954},
  year={2024}
}

@article{kim2024openvla,
  title={Openvla: An open-source vision-language-action model},
  author={Kim, Moo Jin and Pertsch, Karl and Karamcheti, Siddharth and Xiao, Ted and Balakrishna, Ashwin and Nair, Suraj and Rafailov, Rafael and Foster, Ethan and Lam, Grace and Sanketi, Pannag and others},
  journal={arXiv preprint arXiv:2406.09246},
  year={2024}
}

@article{wen2024diffusion,
  title={Diffusion-VLA: Generalizable and Interpretable Robot Foundation Model via Self-Generated Reasoning},
  author={Wen, Junjie and Zhu, Minjie and Zhu, Yichen and Tang, Zhibin and Li, Jinming and Zhou, Zhongyi and Li, Chengmeng and Liu, Xiaoyu and Peng, Yaxin and Shen, Chaomin and others},
  journal={arXiv preprint arXiv:2412.03293},
  year={2024}
}

@article{liu2024rdt,
  title={Rdt-1b: a diffusion foundation model for bimanual manipulation},
  author={Liu, Songming and Wu, Lingxuan and Li, Bangguo and Tan, Hengkai and Chen, Huayu and Wang, Zhengyi and Xu, Ke and Su, Hang and Zhu, Jun},
  journal={arXiv preprint arXiv:2410.07864},
  year={2024}
}

@article{black2410pi0,
  title={pi0: A vision-language-action flow model for general robot control},
  author={Black, Kevin and Brown, Noah and Driess, Danny and Esmail, Adnan and Equi, Michael and Finn, Chelsea and Fusai, Niccolo and Groom, Lachy and Hausman, Karol and Ichter, Brian and others},
  journal={arXiv preprint arXiv:2410.24164},
  year={2024}
}

@article{wu2024robomind,
  title={Robomind: Benchmark on multi-embodiment intelligence normative data for robot manipulation},
  author={Wu, Kun and Hou, Chengkai and Liu, Jiaming and Che, Zhengping and Ju, Xiaozhu and Yang, Zhuqin and Li, Meng and Zhao, Yinuo and Xu, Zhiyuan and Yang, Guang and others},
  journal={arXiv preprint arXiv:2412.13877},
  year={2024}
}

@inproceedings{li2024manipllm,
  title={Manipllm: Embodied multimodal large language model for object-centric robotic manipulation},
  author={Li, Xiaoqi and Zhang, Mingxu and Geng, Yiran and Geng, Haoran and Long, Yuxing and Shen, Yan and Zhang, Renrui and Liu, Jiaming and Dong, Hao},
  booktitle=CVPR,
  pages={18061--18070},
  year={2024}
}

@article{lee2024behavior,
  title={Behavior generation with latent actions},
  author={Lee, Seungjae and Wang, Yibin and Etukuru, Haritheja and Kim, H Jin and Shafiullah, Nur Muhammad Mahi and Pinto, Lerrel},
  journal={arXiv preprint arXiv:2403.03181},
  year={2024}
}

@article{han2024dual,
  title={A dual process vla: Efficient robotic manipulation leveraging vlm},
  author={Han, ByungOk and Kim, Jaehong and Jang, Jinhyeok},
  journal={arXiv preprint arXiv:2410.15549},
  year={2024}
}

@article{khazatsky2024droid,
  title={Droid: A large-scale in-the-wild robot manipulation dataset},
  author={Khazatsky, Alexander and Pertsch, Karl and Nair, Suraj and Balakrishna, Ashwin and Dasari, Sudeep and Karamcheti, Siddharth and Nasiriany, Soroush and Srirama, Mohan Kumar and Chen, Lawrence Yunliang and Ellis, Kirsty and others},
  journal={arXiv preprint arXiv:2403.12945},
  year={2024}
}

@article{team2025gemini,
  title={Gemini robotics: Bringing ai into the physical world},
  author={Team, Gemini Robotics and Abeyruwan, Saminda and Ainslie, Joshua and Alayrac, Jean-Baptiste and Arenas, Montserrat Gonzalez and Armstrong, Travis and Balakrishna, Ashwin and Baruch, Robert and Bauza, Maria and Blokzijl, Michiel and others},
  journal={arXiv preprint arXiv:2503.20020},
  year={2025}
}

@inproceedings{ji2025robobrain,
  title={Robobrain: A unified brain model for robotic manipulation from abstract to concrete},
  author={Ji, Yuheng and Tan, Huajie and Shi, Jiayu and Hao, Xiaoshuai and Zhang, Yuan and Zhang, Hengyuan and Wang, Pengwei and Zhao, Mengdi and Mu, Yao and An, Pengju and others},
  booktitle=CVPR,
  pages={1724--1734},
  year={2025}
}

@article{zhang2025doglove,
  title={Doglove: Dexterous manipulation with a low-cost open-source haptic force feedback glove},
  author={Zhang, Han and Hu, Songbo and Yuan, Zhecheng and Xu, Huazhe},
  journal={arXiv preprint arXiv:2502.07730},
  year={2025}
}

@article{wen2025tinyvla,
  title={Tinyvla: Towards fast, data-efficient vision-language-action models for robotic manipulation},
  author={Wen, Junjie and Zhu, Yichen and Li, Jinming and Zhu, Minjie and Tang, Zhibin and Wu, Kun and Xu, Zhiyuan and Liu, Ning and Cheng, Ran and Shen, Chaomin and others},
  journal={IEEE Robotics and Automation Letters},
  year={2025},
  publisher={IEEE}
}

@article{wang2025vq,
  title={VQ-VLA: Improving Vision-Language-Action Models via Scaling Vector-Quantized Action Tokenizers},
  author={Wang, Yating and Zhu, Haoyi and Liu, Mingyu and Yang, Jiange and Fang, Hao-Shu and He, Tong},
  journal={arXiv preprint arXiv:2507.01016},
  year={2025}
}

@article{luo2025precise,
  title={Precise and dexterous robotic manipulation via human-in-the-loop reinforcement learning},
  author={Luo, Jianlan and Xu, Charles and Wu, Jeffrey and Levine, Sergey},
  journal={Science Robotics},
  volume={10},
  number={105},
  pages={eads5033},
  year={2025},
  publisher={American Association for the Advancement of Science}
}

@article{bjorck2025gr00t,
  title={Gr00t n1: An open foundation model for generalist humanoid robots},
  author={Bjorck, Johan and Casta{\~n}eda, Fernando and Cherniadev, Nikita and Da, Xingye and Ding, Runyu and Fan, Linxi and Fang, Yu and Fox, Dieter and Hu, Fengyuan and Huang, Spencer and others},
  journal={arXiv preprint arXiv:2503.14734},
  year={2025}
}

@article{jang2025dreamgen,
  title={DreamGen: Unlocking Generalization in Robot Learning through Video World Models},
  author={Jang, Joel and Ye, Seonghyeon and Lin, Zongyu and Xiang, Jiannan and Bjorck, Johan and Fang, Yu and Hu, Fengyuan and Huang, Spencer and Kundalia, Kaushil and Lin, Yen-Chen and others},
  journal={arXiv preprint arXiv:2505.12705},
  year={2025}
}

@article{he2025dexvlg,
  title={DexVLG: Dexterous Vision-Language-Grasp Model at Scale},
  author={He, Jiawei and Li, Danshi and Yu, Xinqiang and Qi, Zekun and Zhang, Wenyao and Chen, Jiayi and Zhang, Zhaoxiang and Zhang, Zhizheng and Yi, Li and Wang, He},
  journal={arXiv preprint arXiv:2507.02747},
  year={2025}
}

@article{yang2025egovla,
  title={Egovla: Learning vision-language-action models from egocentric human videos},
  author={Yang, Ruihan and Yu, Qinxi and Wu, Yecheng and Yan, Rui and Li, Borui and Cheng, An-Chieh and Zou, Xueyan and Fang, Yunhao and Cheng, Xuxin and Qiu, Ri-Zhao and others},
  journal={arXiv preprint arXiv:2507.12440},
  year={2025}
}

@article{pertsch2025fast,
  title={Fast: Efficient action tokenization for vision-language-action models},
  author={Pertsch, Karl and Stachowicz, Kyle and Ichter, Brian and Driess, Danny and Nair, Suraj and Vuong, Quan and Mees, Oier and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:2501.09747},
  year={2025}
}

@mastersthesis{yang2025ace,
  title={ACE: A Cross-platform Visual-Exoskeleton System for Low-Cost Dexterous Teleoperation},
  author={Yang, Shiqi},
  year={2025},
  school={University of California, San Diego}
}

@article{liu2025hybridvla,
  title={Hybridvla: Collaborative diffusion and autoregression in a unified vision-language-action model},
  author={Liu, Jiaming and Chen, Hao and An, Pengju and Liu, Zhuoyang and Zhang, Renrui and Gu, Chenyang and Li, Xiaoqi and Guo, Ziyu and Chen, Sixiang and Liu, Mengzhen and others},
  journal={arXiv preprint arXiv:2503.10631},
  year={2025}
}

@article{hou2025dita,
  title={Dita: Scaling diffusion transformer for generalist vision-language-action policy},
  author={Hou, Zhi and Zhang, Tianyi and Xiong, Yuwen and Duan, Haonan and Pu, Hengjun and Tong, Ronglei and Zhao, Chengyang and Zhu, Xizhou and Qiao, Yu and Dai, Jifeng and others},
  journal={arXiv preprint arXiv:2503.19757},
  year={2025}
}

@article{jiang2025kaiwu,
  title={Kaiwu: A Multimodal Manipulation Dataset and Framework for Robot Learning and Human-Robot Interaction},
  author={Jiang, Shuo and Li, Haonan and Ren, Ruochen and Zhou, Yanmin and Wang, Zhipeng and He, Bin},
  journal={arXiv preprint arXiv:2503.05231},
  year={2025}
}

@article{gao2025glovity,
  title={Glovity: Learning Dexterous Contact-Rich Manipulation via Spatial Wrench Feedback Teleoperation System},
  author={Gao, Yuyang and Ma, Haofei and Zheng, Pai},
  journal={arXiv preprint arXiv:2510.09229},
  year={2025}
}

@article{xu2025dexumi,
  title={DexUMI: Using Human Hand as the Universal Manipulation Interface for Dexterous Manipulation},
  author={Xu, Mengda and Zhang, Han and Hou, Yifan and Xu, Zhenjia and Fan, Linxi and Veloso, Manuela and Song, Shuran},
  journal={arXiv preprint arXiv:2505.21864},
  year={2025}
}

@article{bu2025agibot,
  title={Agibot world colosseo: A large-scale manipulation platform for scalable and intelligent embodied systems},
  author={Bu, Qingwen and Cai, Jisong and Chen, Li and Cui, Xiuqi and Ding, Yan and Feng, Siyuan and Gao, Shenyuan and He, Xindong and Hu, Xuan and Huang, Xu and others},
  journal={arXiv preprint arXiv:2503.06669},
  year={2025}
}

@inproceedings{chen2025vidbot,
  title={VidBot: Learning Generalizable 3D Actions from In-the-Wild 2D Human Videos for Zero-Shot Robotic Manipulation},
  author={Chen, Hanzhi and Sun, Boyang and Zhang, Anran and Pollefeys, Marc and Leutenegger, Stefan},
  booktitle=CVPR,
  pages={27661--27672},
  year={2025}
}

@article{zhong2025dexgraspvla,
  title={Dexgraspvla: A vision-language-action framework towards general dexterous grasping},
  author={Zhong, Yifan and Huang, Xuchuan and Li, Ruochong and Zhang, Ceyao and Chen, Zhang and Guan, Tianrui and Zeng, Fanlian and Lui, Ka Num and Ye, Yuyao and Liang, Yitao and others},
  journal={arXiv preprint arXiv:2502.20900},
  year={2025}
}

@article{wen2025dexvla,
  title={Dexvla: Vision-language model with plug-in diffusion expert for general robot control},
  author={Wen, Junjie and Zhu, Yichen and Li, Jinming and Tang, Zhibin and Shen, Chaomin and Feng, Feifei},
  journal={arXiv preprint arXiv:2502.05855},
  year={2025}
}

@article{fourier2025actionnet,
  author    = {Fourier ActionNet Team, Yao Mu},
  title     = {ActionNet: A dataset for dexterous bimanual manipulation},
  year      = {2025},
}

@inproceedings{zheng2025universal,
  title={Universal actions for enhanced embodied foundation models},
  author={Zheng, Jinliang and Li, Jianxiong and Liu, Dongxiu and Zheng, Yinan and Wang, Zhihao and Ou, Zhonghong and Liu, Yu and Liu, Jingjing and Zhang, Ya-Qin and Zhan, Xianyuan},
  booktitle=CVPR,
  pages={22508--22519},
  year={2025}
}

@inproceedings{yan2025maniflow,
  title={{ManiFlow}: A General Robot Manipulation Policy via Consistency Flow Training},
  author={Yan, Ge and Zhu, Jiyue and Deng, Yuquan and Yang, Shiqi and Qiu, Ri-Zhao and Cheng, Xuxin and Memmel, Marius and Krishna, Ranjay and Goyal, Ankit and Wang, Xiaolong and Fox, Dieter},
  booktitle=CORL,
  year={2025}
}

@inproceedings{zhao2025cot,
  title={Cot-vla: Visual chain-of-thought reasoning for vision-language-action models},
  author={Zhao, Qingqing and Lu, Yao and Kim, Moo Jin and Fu, Zipeng and Zhang, Zhuoyang and Wu, Yecheng and Li, Zhaoshuo and Ma, Qianli and Han, Song and Finn, Chelsea and others},
  booktitle=CVPR,
  pages={1702--1713},
  year={2025}
}

@article{li2025bridgevla,
  title={BridgeVLA: Input-Output Alignment for Efficient 3D Manipulation Learning with Vision-Language Models},
  author={Li, Peiyan and Chen, Yixiang and Wu, Hongtao and Ma, Xiao and Wu, Xiangnan and Huang, Yan and Wang, Liang and Kong, Tao and Tan, Tieniu},
  journal={arXiv preprint arXiv:2506.07961},
  year={2025}
}

@article{li2025pointvla,
  title={Pointvla: Injecting the 3d world into vision-language-action models},
  author={Li, Chengmeng and Wen, Junjie and Peng, Yan and Peng, Yaxin and Feng, Feifei and Zhu, Yichen},
  journal={arXiv preprint arXiv:2503.07511},
  year={2025}
}

@article{intelligence2025pi,
  title={Pi0.5: a Vision-Language-Action Model with Open-World Generalization},
  author={Intelligence, Physical and Black, Kevin and Brown, Noah and Darpinian, James and Dhabalia, Karan and Driess, Danny and Esmail, Adnan and Equi, Michael and Finn, Chelsea and Fusai, Niccolo and others},
  journal={arXiv preprint arXiv:2504.16054},
  year={2025}
}

@inproceedings{zhou2025mitigating,
  title={Mitigating the human-robot domain discrepancy in visual pre-training for robotic manipulation},
  author={Zhou, Jiaming and Ma, Teli and Lin, Kun-Yu and Wang, Zifan and Qiu, Ronghe and Liang, Junwei},
  booktitle=CVPR,
  pages={22551--22561},
  year={2025}
}

@inproceedings{zhou2025physvlm,
  title={Physvlm: Enabling visual language models to understand robotic physical reachability},
  author={Zhou, Weijie and Tao, Manli and Zhao, Chaoyang and Guo, Haiyun and Dong, Honghui and Tang, Ming and Wang, Jinqiao},
  booktitle=CVPR,
  pages={6940--6949},
  year={2025}
}

@inproceedings{qian20253d,
  title={3D-MVP: 3D Multiview Pretraining for Manipulation},
  author={Qian, Shengyi and Mo, Kaichun and Blukis, Valts and Fouhey, David F and Fox, Dieter and Goyal, Ankit},
  booktitle=CVPR,
  pages={22530--22539},
  year={2025}
}
